{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "u827SkBgbc6H"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import numpy as np\n",
        "from keras.layers import *\n",
        "from keras.models import Sequential\n",
        "import keras.utils"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Буквы"
      ],
      "metadata": {
        "id": "AJ_DoS7WyXex"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qYRSRktqbc6J"
      },
      "outputs": [],
      "source": [
        "with open('05 train_data.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "    text = text.replace('\\ufeff', '')  # убираем первый невидимый символ\n",
        "    text = text.replace('\\n', ' ')  # заменяем перевод строки на пробел\n",
        "    text = re.sub(r'[^А-я ]', '', text)  # убираем все недопустимые символы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "TB2gHn3mbc6K",
        "outputId": "c9006df9-546d-45de-fb64-99d476b1d990"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Вы  лучший ответ на проблемы которые возникли в понедельник Думайте позитивно и верьте в свою способность достигать отличных результатов Если вы смогли в понедельник подняться с постели значит вы супер герой'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0qR_J5-zbc6M"
      },
      "outputs": [],
      "source": [
        "num_characters = 34  # 33 буквы + пробел\n",
        "tokenizer = Tokenizer(num_words=num_characters, char_level=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dn3R4P_Rbc6N",
        "outputId": "09cd5133-1856-412e-fc91-9778f08f3218"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 1, 'о': 2, 'т': 3, 'е': 4, 'и': 5, 'в': 6, 'н': 7, 'с': 8, 'л': 9, 'п': 10, 'ь': 11, 'ы': 12, 'р': 13, 'а': 14, 'д': 15, 'у': 16, 'к': 17, 'з': 18, 'ч': 19, 'й': 20, 'м': 21, 'г': 22, 'б': 23, 'я': 24, 'ш': 25, 'ю': 26, 'х': 27}\n"
          ]
        }
      ],
      "source": [
        "tokenizer.fit_on_texts(text)\n",
        "print(tokenizer.word_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "MXOvKHJmbc6O"
      },
      "outputs": [],
      "source": [
        "inp_chars = 7\n",
        "data = tokenizer.texts_to_matrix(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LocuV_gVbc6O"
      },
      "outputs": [],
      "source": [
        "n = data.shape[0]-inp_chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "yTI6P9Odbc6P"
      },
      "outputs": [],
      "source": [
        "X = np.array([data[i:i+inp_chars, :] for i in range(n)])\n",
        "Y = data[inp_chars:]  # предсказание следующего символа"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkpupFiwbc6P",
        "outputId": "f566c684-a2c6-4abe-c556-a4e8b6cb16a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_1 (SimpleRNN)    (None, 500)               267500    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 34)                17034     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 284534 (1.09 MB)\n",
            "Trainable params: 284534 (1.09 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Input((inp_chars, num_characters)))\n",
        "model.add(SimpleRNN(500, activation='tanh'))\n",
        "model.add(Dense(num_characters, activation='softmax'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcUkd_0Qbc6Q",
        "outputId": "70b22105-9ef3-4a39-e5e5-d1b36766ea49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "7/7 [==============================] - 1s 15ms/step - loss: 3.3952 - accuracy: 0.0700\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 2.3937 - accuracy: 0.3250\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 1.8742 - accuracy: 0.5400\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 1.5052 - accuracy: 0.5650\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 1.1793 - accuracy: 0.6750\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.9856 - accuracy: 0.7150\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.8157 - accuracy: 0.8150\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.7076 - accuracy: 0.7950\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6185 - accuracy: 0.8550\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.5430 - accuracy: 0.8550\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.4313 - accuracy: 0.9050\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3452 - accuracy: 0.9400\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3387 - accuracy: 0.9400\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.3559 - accuracy: 0.9350\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2764 - accuracy: 0.9300\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.3284 - accuracy: 0.9150\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2650 - accuracy: 0.9550\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.2437 - accuracy: 0.9450\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2010 - accuracy: 0.9550\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.2824 - accuracy: 0.9550\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2401 - accuracy: 0.9550\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2699 - accuracy: 0.9650\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.2499 - accuracy: 0.9600\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.1641 - accuracy: 0.9600\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.1331 - accuracy: 0.9750\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.1413 - accuracy: 0.9700\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.1839 - accuracy: 0.9800\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.1308 - accuracy: 0.9800\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.1986 - accuracy: 0.9600\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.1517 - accuracy: 0.9750\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.1334 - accuracy: 0.9650\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.1634 - accuracy: 0.9650\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.1389 - accuracy: 0.9750\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.1310 - accuracy: 0.9700\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0937 - accuracy: 0.9800\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0564 - accuracy: 0.9900\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0678 - accuracy: 0.9850\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0492 - accuracy: 0.9900\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0432 - accuracy: 0.9900\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0407 - accuracy: 0.9950\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0390 - accuracy: 0.9900\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0418 - accuracy: 0.9900\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0281 - accuracy: 0.9950\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0721 - accuracy: 0.9900\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0517 - accuracy: 0.9900\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0369 - accuracy: 0.9900\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0480 - accuracy: 0.9900\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0524 - accuracy: 0.9900\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0378 - accuracy: 0.9900\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0512 - accuracy: 0.9900\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0309 - accuracy: 0.9950\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0318 - accuracy: 0.9950\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0240 - accuracy: 0.9950\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0258 - accuracy: 0.9950\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0236 - accuracy: 0.9950\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0270 - accuracy: 0.9900\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0246 - accuracy: 0.9950\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0288 - accuracy: 0.9950\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0369 - accuracy: 0.9900\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0202 - accuracy: 0.9950\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0697 - accuracy: 0.9850\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0486 - accuracy: 0.9900\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0314 - accuracy: 0.9900\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0247 - accuracy: 0.9950\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0285 - accuracy: 0.9900\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0221 - accuracy: 0.9900\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0214 - accuracy: 0.9950\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0189 - accuracy: 0.9950\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0191 - accuracy: 0.9950\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0184 - accuracy: 0.9950\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0254 - accuracy: 0.9900\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0206 - accuracy: 0.9950\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0255 - accuracy: 0.9850\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0265 - accuracy: 0.9850\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0205 - accuracy: 0.9850\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0351 - accuracy: 0.9900\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0294 - accuracy: 0.9900\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0166 - accuracy: 0.9950\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0244 - accuracy: 0.9950\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0300 - accuracy: 0.9950\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0260 - accuracy: 0.9950\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0210 - accuracy: 0.9950\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0199 - accuracy: 0.9900\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0174 - accuracy: 0.9950\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0156 - accuracy: 0.9950\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0156 - accuracy: 0.9950\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0146 - accuracy: 0.9950\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0214 - accuracy: 0.9950\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0229 - accuracy: 0.9950\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0209 - accuracy: 0.9950\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0138 - accuracy: 0.9950\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0144 - accuracy: 0.9950\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0142 - accuracy: 0.9950\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0142 - accuracy: 0.9950\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 9ms/step - loss: 0.0175 - accuracy: 0.9900\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0164 - accuracy: 0.9900\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0145 - accuracy: 0.9950\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0149 - accuracy: 0.9950\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0122 - accuracy: 0.9950\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0130 - accuracy: 0.9900\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(X, Y, batch_size=32, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "b8J5n78AwfnJ"
      },
      "outputs": [],
      "source": [
        "def buildPharse(inp_str, str_len=50):\n",
        "    for i in range(str_len):\n",
        "        x=[]\n",
        "        for j in range(i, i+inp_chars):\n",
        "            x.append(tokenizer.texts_to_matrix(inp_str[j])) # преобразуем символы в OneHot encoding\n",
        "        x=np.array(x)\n",
        "        inp=x.reshape(1, inp_chars,num_characters)\n",
        "        pred=model.predict(inp) # предсказываем ОНЕ четвёртого символа\n",
        "        d=tokenizer.index_word[pred.argmax(axis=1)[0]] # получаем ответ в символьном представлении\n",
        "        inp_str+=d # дописываем строку\n",
        "    return inp_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUz75-v5wfnK",
        "outputId": "33e5ab92-84eb-47fc-afb7-55a34fd1192f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 98ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "проблемы которые возникли в понедельник подняться с посте\n"
          ]
        }
      ],
      "source": [
        "res=buildPharse('проблем')\n",
        "print(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "увеличив количество букв, на основании которых сеть даёт предсказание - получили почти осмысленный текст"
      ],
      "metadata": {
        "id": "CCf2ap6OwEZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res=buildPharse('лучший ответ')\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZYf2r80wZUJ",
        "outputId": "b02c8265-d8dc-48ed-8991-8415f6aef280"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "лучший ответответ на писа проблеистлемы кои глоторыпотопо возн\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Уже менее осмысленно"
      ],
      "metadata": {
        "id": "yN2T0kV2wYVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res=buildPharse('Думайте позитивно')\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdUOYPkMxNG8",
        "outputId": "de3c8c53-08bb-4ca1-fd69-313e526e2e9d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Думайте позитивно позитивно и вернвно и верьте в   ерьте в своюдеен\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res=buildPharse('он герой')\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MH5XcA24xpsC",
        "outputId": "9f4e68a4-e1d3-42c6-e157-cf630504bc8c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "он геройното сы свооелиплвначиос еы втонери линою е меробт\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Уже совсем не то.<br>\n",
        "Вероятно надо больший объём тренирочного текста.<br>\n",
        "Ну и более сложную сеть."
      ],
      "metadata": {
        "id": "xg2QYHnwxz6Z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yhmbaRgwfnL"
      },
      "source": [
        "# Слова"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "AUYrbROywfnM",
        "outputId": "0c6e5411-188a-41b7-8c1f-5fab9855dd7b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Вы  лучший ответ на проблемы которые возникли в понедельник Думайте позитивно и верьте в свою способность достигать отличных результатов Если вы смогли в понедельник подняться с постели значит вы супер герой'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "with open('05 train_data.txt', 'r', encoding='utf-8') as f:\n",
        "    texts = f.read()\n",
        "    texts = texts.replace('\\ufeff', '')  # убираем первый невидимый символ\n",
        "    texts = texts.replace('\\n', ' ')  # заменяем перевод строки на пробел\n",
        "    texts = texts.lower()\n",
        "    texts = re.sub(r'[^А-я ]', '', texts)  # убираем все недопустимые символы\n",
        "texts"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maxWordsCount=1000"
      ],
      "metadata": {
        "id": "A7mFFLWOyih_"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "yTe6_YR8wfnN"
      },
      "outputs": [],
      "source": [
        "tokenizerWord = Tokenizer(num_words=maxWordsCount, char_level=False)\n",
        "tokenizerWord.fit_on_texts([texts])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25ihkalswfnN",
        "outputId": "d5e8838e-9889-441e-c08e-60cafd73330d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('вы', 3), ('лучший', 1), ('ответ', 1), ('на', 1), ('проблемы', 1), ('которые', 1), ('возникли', 1), ('в', 3), ('понедельник', 2), ('думайте', 1), ('позитивно', 1), ('и', 1), ('верьте', 1), ('свою', 1), ('способность', 1), ('достигать', 1), ('отличных', 1), ('результатов', 1), ('если', 1), ('смогли', 1), ('подняться', 1), ('с', 1), ('постели', 1), ('значит', 1), ('супер', 1), ('герой', 1)]\n"
          ]
        }
      ],
      "source": [
        "dist=list(tokenizerWord.word_counts.items())\n",
        "print(dist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGXW68y9wfnO",
        "outputId": "c6c316f8-aad5-41fd-f6a3-c196b68cc3bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(31, 1000)\n"
          ]
        }
      ],
      "source": [
        "data=tokenizerWord.texts_to_sequences([texts])\n",
        "res=keras.utils.to_categorical(data[0], num_classes=maxWordsCount)\n",
        "print(res.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICXzldoJAYT8",
        "outputId": "cef1495d-eee6-4468-d366-4e4fba932170"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "HopIU3BlwfnO"
      },
      "outputs": [],
      "source": [
        "inp_words = 3\n",
        "n = res.shape[0]-inp_words\n",
        "X = np.array([res[i:i+inp_words, :] for i in range(n)])\n",
        "Y = res[inp_words:]  # предсказание следующего слова"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArJxHKu9wfnO",
        "outputId": "e16d320d-0e0d-4c13-fcc5-3967c97179a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_2 (SimpleRNN)    (None, 128)               144512    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1000)              129000    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 273512 (1.04 MB)\n",
            "Trainable params: 273512 (1.04 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Input((inp_words, maxWordsCount)))\n",
        "model.add(SimpleRNN(128, activation='tanh'))\n",
        "model.add(Dense(maxWordsCount, activation='softmax'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXHlWnj_wfnP",
        "outputId": "4da9a8b5-439c-45b4-979a-d30cdbfbccc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 2.5896 - accuracy: 0.3571\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.5272 - accuracy: 0.3571\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.4667 - accuracy: 0.3929\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.4057 - accuracy: 0.4643\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.3435 - accuracy: 0.5357\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.2806 - accuracy: 0.6071\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.2175 - accuracy: 0.6429\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.1553 - accuracy: 0.6786\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.0947 - accuracy: 0.7500\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.0362 - accuracy: 0.7857\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.9798 - accuracy: 0.8214\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.9251 - accuracy: 0.8571\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.8712 - accuracy: 0.9286\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.8169 - accuracy: 0.9286\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.7613 - accuracy: 0.9286\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.7038 - accuracy: 0.9286\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6444 - accuracy: 0.9286\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.5837 - accuracy: 0.9286\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.5223 - accuracy: 0.9286\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.4611 - accuracy: 0.9286\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4006 - accuracy: 0.9286\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.3410 - accuracy: 0.9286\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.2826 - accuracy: 0.9286\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.2253 - accuracy: 0.9286\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1691 - accuracy: 0.9286\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1138 - accuracy: 0.9286\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.0595 - accuracy: 0.9286\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0064 - accuracy: 0.9286\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.9545 - accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.9042 - accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8556 - accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8088 - accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7640 - accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7213 - accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6807 - accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6422 - accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6058 - accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5714 - accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5390 - accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5085 - accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4798 - accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4529 - accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4276 - accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4040 - accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3819 - accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3613 - accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3420 - accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3240 - accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3072 - accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2915 - accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(X, Y, batch_size=32, epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "GpPNF5FEwfnP"
      },
      "outputs": [],
      "source": [
        "def buildPharseWords(text, str_len=4):\n",
        "    res=text\n",
        "    data=tokenizerWord.texts_to_sequences(text)\n",
        "    # так как получаем data вида [[],[],[3],[]], то есть часть элементов имеют нулевую длину, а значит неопределены\n",
        "    # потому впишем туда значение 0\n",
        "    for j in range(len(data)):\n",
        "      if len(data[j])==0:\n",
        "        data[j].append(0)\n",
        "    for i in range(str_len):\n",
        "      x=keras.utils.to_categorical(data[i:i+inp_words], num_classes=maxWordsCount) # преобразуем слова в OneHot encoding\n",
        "      inp=x.reshape(1, inp_words,maxWordsCount)\n",
        "      pred=model.predict(inp) # предсказываем ОНЕ четвёртого слова\n",
        "      indx=pred.argmax(axis=1)[0]\n",
        "      data.append([indx])\n",
        "      res+=' '+dist[indx][0] # дописываем строку - достаём из списка кортежей по индексу значение слова\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLQebfGdwfnQ",
        "outputId": "3a023eb0-d7ed-49e7-bddf-b0bd2ee82d5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 96ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "голубые слоны мавритании достигать понедельник верьте результатов\n"
          ]
        }
      ],
      "source": [
        "res=buildPharseWords('голубые слоны мавритании')\n",
        "print(res)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res=buildPharseWords('лучший ответ на проблемы')\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlnfx3HXzkIp",
        "outputId": "9f510f60-f8a6-4ba5-a7f5-3c96da62a175"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "лучший ответ на проблемы достигать отличных герой позитивно\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "косноязычный текст - так как малый набор слов в словарном запасе сети."
      ],
      "metadata": {
        "id": "9ixepf8Ez9TI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=tokenizerWord.texts_to_sequences([texts])\n",
        "res=keras.utils.to_categorical(data[0], num_classes=maxWordsCount)\n",
        "inp_words = 6\n",
        "n = res.shape[0]-inp_words\n",
        "X = np.array([res[i:i+inp_words, :] for i in range(n)])\n",
        "Y = res[inp_words:]  # предсказание следующего слова\n",
        "model = Sequential()\n",
        "model.add(Input((inp_words, maxWordsCount)))\n",
        "model.add(SimpleRNN(512, activation='tanh'))\n",
        "model.add(Dense(maxWordsCount, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(X, Y, batch_size=32, epochs=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "133SOMtA0Fxh",
        "outputId": "563dad79-f949-4ef0-8dba-eadc6390b722"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_3 (SimpleRNN)    (None, 512)               774656    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1000)              513000    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1287656 (4.91 MB)\n",
            "Trainable params: 1287656 (4.91 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 6.9262 - accuracy: 0.0000e+00\n",
            "Epoch 2/30\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 6.6382 - accuracy: 0.7200\n",
            "Epoch 3/30\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 6.3367 - accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 5.9928 - accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 5.5707 - accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 5.0229 - accuracy: 0.9600\n",
            "Epoch 7/30\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 4.2940 - accuracy: 0.9200\n",
            "Epoch 8/30\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.3771 - accuracy: 0.9200\n",
            "Epoch 9/30\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.4980 - accuracy: 0.8000\n",
            "Epoch 10/30\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.0413 - accuracy: 0.5600\n",
            "Epoch 11/30\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.7200 - accuracy: 0.6400\n",
            "Epoch 12/30\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.3039 - accuracy: 0.8000\n",
            "Epoch 13/30\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.8685 - accuracy: 0.9600\n",
            "Epoch 14/30\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5322 - accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.3363 - accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2412 - accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1914 - accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1553 - accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1247 - accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1011 - accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0842 - accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0707 - accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0577 - accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0458 - accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0368 - accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0305 - accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0253 - accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0205 - accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0167 - accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0140 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def buildPharseWords(text, str_len=4):\n",
        "    res=text\n",
        "    data=tokenizerWord.texts_to_sequences(text)\n",
        "    # так как получаем data вида [[],[],[3],[]], то есть часть элементов имеют нулевую длину, а значит неопределены\n",
        "    # потому впишем туда значение 0\n",
        "    for j in range(len(data)):\n",
        "      if len(data[j])==0:\n",
        "        data[j].append(0)\n",
        "    for i in range(str_len):\n",
        "      x=keras.utils.to_categorical(data[i:i+inp_words], num_classes=maxWordsCount) # преобразуем слова в OneHot encoding\n",
        "      inp=x.reshape(1, inp_words,maxWordsCount)\n",
        "      pred=model.predict(inp) # предсказываем ОНЕ четвёртого слова\n",
        "      indx=pred.argmax(axis=1)[0]\n",
        "      data.append([indx])\n",
        "      res+=' '+dist[indx][0] # дописываем строку - достаём из списка кортежей по индексу значение слова\n",
        "    return res"
      ],
      "metadata": {
        "id": "r46-40XT0_Yp"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res=buildPharseWords('голубые слоны мавритании')\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njn0qx1f1EF5",
        "outputId": "16690460-21b2-4417-a81c-bc2b91fcdc96"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "голубые слоны мавритании супер лучший свою ответ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def buildPharseWords(text, str_len=25):\n",
        "    res=text\n",
        "    data=tokenizerWord.texts_to_sequences(text)\n",
        "    # так как получаем data вида [[],[],[3],[]], то есть часть элементов имеют нулевую длину, а значит неопределены\n",
        "    # потому впишем туда значение 0\n",
        "    for j in range(len(data)):\n",
        "      if len(data[j])==0:\n",
        "        data[j].append(0)\n",
        "    for i in range(str_len):\n",
        "      x=keras.utils.to_categorical(data[i:i+inp_words], num_classes=maxWordsCount) # преобразуем слова в OneHot encoding\n",
        "      inp=x.reshape(1, inp_words,maxWordsCount)\n",
        "      pred=model.predict(inp) # предсказываем ОНЕ четвёртого слова\n",
        "      indx=pred.argmax(axis=1)[0]\n",
        "      data.append([indx])\n",
        "      print(i,len(data), indx)\n",
        "      res+=' '+dist[indx][0] # дописываем строку - достаём из списка кортежей по индексу значение слова\n",
        "    return res"
      ],
      "metadata": {
        "id": "rKOSTFGt3ZoT"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res=buildPharseWords('Вы  лучший ответ на проблемы которые возникли')\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aw9zR2Hr3cbC",
        "outputId": "c15ab0c6-9070-4ecc-d9c5-bc0c1e57e1cb"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "0 46 10\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1 47 17\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2 48 9\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3 49 23\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "4 50 13\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "5 51 2\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "6 52 22\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "7 53 2\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "8 54 3\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "9 55 24\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "10 56 9\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "11 57 2\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "12 58 14\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "13 59 10\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "14 60 2\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "15 61 25\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "16 62 23\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "17 63 11\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "18 64 1\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "19 65 23\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "20 66 15\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "21 67 18\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "22 68 2\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "23 69 12\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "24 70 13\n",
            "Вы  лучший ответ на проблемы которые возникли позитивно результатов думайте значит свою ответ постели ответ на супер думайте ответ способность позитивно ответ герой значит и лучший значит достигать если ответ верьте свою\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Из-за малого словарного запаса, ни увеличение нейронов сети, ни увеличение количества слов-оснований предсказания заметно не улучшают качество выдаваемого текста"
      ],
      "metadata": {
        "id": "efSX009F567u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('текст.txt', 'r', encoding='utf-8') as f:\n",
        "    texts = f.read()\n",
        "    # texts = text.replace('\\ufeff', '')  # убираем первый невидимый символ\n",
        "    texts = texts.replace('\\n', ' ')  # заменяем перевод строки на пробел\n",
        "    texts = texts.lower()\n",
        "    texts = re.sub(r'[^А-я ]', '', texts)  # убираем все недопустимые символы"
      ],
      "metadata": {
        "id": "5jCAhSBK7FFi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxWordsCount=1000\n",
        "tokenizerWord = Tokenizer(num_words=maxWordsCount, char_level=False)\n",
        "tokenizerWord.fit_on_texts([texts])\n",
        "data=tokenizerWord.texts_to_sequences([texts])\n",
        "res=keras.utils.to_categorical(data[0], num_classes=maxWordsCount)\n",
        "inp_words = 6\n",
        "n = res.shape[0]-inp_words\n",
        "X = np.array([res[i:i+inp_words, :] for i in range(n)])\n",
        "Y = res[inp_words:]  # предсказание следующего слова\n",
        "model = Sequential()\n",
        "model.add(Input((inp_words, maxWordsCount)))\n",
        "model.add(SimpleRNN(512, activation='tanh'))\n",
        "model.add(Dense(maxWordsCount, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(X, Y, batch_size=32, epochs=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXqQG3iM66Fq",
        "outputId": "5c1e7b63-7593-4a1a-db24-11b90518babb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn (SimpleRNN)      (None, 512)               774656    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1000)              513000    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1287656 (4.91 MB)\n",
            "Trainable params: 1287656 (4.91 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "1529/1529 [==============================] - 37s 24ms/step - loss: 5.7329 - accuracy: 0.0573\n",
            "Epoch 2/30\n",
            "1529/1529 [==============================] - 36s 24ms/step - loss: 5.4227 - accuracy: 0.0809\n",
            "Epoch 3/30\n",
            "1529/1529 [==============================] - 37s 24ms/step - loss: 5.1132 - accuracy: 0.1037\n",
            "Epoch 4/30\n",
            "1529/1529 [==============================] - 39s 25ms/step - loss: 4.7692 - accuracy: 0.1180\n",
            "Epoch 5/30\n",
            "1529/1529 [==============================] - 38s 25ms/step - loss: 4.3946 - accuracy: 0.1424\n",
            "Epoch 6/30\n",
            "1529/1529 [==============================] - 37s 24ms/step - loss: 4.0032 - accuracy: 0.1772\n",
            "Epoch 7/30\n",
            "1529/1529 [==============================] - 36s 23ms/step - loss: 3.6488 - accuracy: 0.2176\n",
            "Epoch 8/30\n",
            "1529/1529 [==============================] - 37s 24ms/step - loss: 3.3302 - accuracy: 0.2589\n",
            "Epoch 9/30\n",
            "1529/1529 [==============================] - 36s 24ms/step - loss: 3.0711 - accuracy: 0.2994\n",
            "Epoch 10/30\n",
            "1529/1529 [==============================] - 36s 24ms/step - loss: 2.8383 - accuracy: 0.3349\n",
            "Epoch 11/30\n",
            "1529/1529 [==============================] - 36s 24ms/step - loss: 2.6478 - accuracy: 0.3692\n",
            "Epoch 12/30\n",
            "1529/1529 [==============================] - 37s 24ms/step - loss: 2.4782 - accuracy: 0.3962\n",
            "Epoch 13/30\n",
            "1529/1529 [==============================] - 36s 24ms/step - loss: 2.3258 - accuracy: 0.4277\n",
            "Epoch 14/30\n",
            "1529/1529 [==============================] - 36s 24ms/step - loss: 2.1941 - accuracy: 0.4507\n",
            "Epoch 15/30\n",
            "1529/1529 [==============================] - 36s 24ms/step - loss: 2.0866 - accuracy: 0.4701\n",
            "Epoch 16/30\n",
            "1529/1529 [==============================] - 37s 24ms/step - loss: 1.9860 - accuracy: 0.4881\n",
            "Epoch 17/30\n",
            "1529/1529 [==============================] - 38s 25ms/step - loss: 1.8930 - accuracy: 0.5077\n",
            "Epoch 18/30\n",
            "1529/1529 [==============================] - 36s 24ms/step - loss: 1.8041 - accuracy: 0.5264\n",
            "Epoch 19/30\n",
            "1529/1529 [==============================] - 36s 24ms/step - loss: 1.7190 - accuracy: 0.5430\n",
            "Epoch 20/30\n",
            "1529/1529 [==============================] - 37s 24ms/step - loss: 1.6725 - accuracy: 0.5561\n",
            "Epoch 21/30\n",
            "1529/1529 [==============================] - 36s 24ms/step - loss: 1.5950 - accuracy: 0.5731\n",
            "Epoch 22/30\n",
            "1529/1529 [==============================] - 37s 24ms/step - loss: 1.5237 - accuracy: 0.5887\n",
            "Epoch 23/30\n",
            "1529/1529 [==============================] - 36s 24ms/step - loss: 1.4847 - accuracy: 0.5973\n",
            "Epoch 24/30\n",
            "1529/1529 [==============================] - 36s 24ms/step - loss: 1.4237 - accuracy: 0.6140\n",
            "Epoch 25/30\n",
            "1529/1529 [==============================] - 36s 24ms/step - loss: 1.3787 - accuracy: 0.6224\n",
            "Epoch 26/30\n",
            "1529/1529 [==============================] - 36s 24ms/step - loss: 1.3307 - accuracy: 0.6326\n",
            "Epoch 27/30\n",
            "1529/1529 [==============================] - 36s 24ms/step - loss: 1.2850 - accuracy: 0.6417\n",
            "Epoch 28/30\n",
            "1529/1529 [==============================] - 36s 24ms/step - loss: 1.2507 - accuracy: 0.6526\n",
            "Epoch 29/30\n",
            "1529/1529 [==============================] - 37s 24ms/step - loss: 1.2281 - accuracy: 0.6576\n",
            "Epoch 30/30\n",
            "1529/1529 [==============================] - 36s 23ms/step - loss: 1.1853 - accuracy: 0.6657\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dist=list(tokenizerWord.word_counts.items())\n",
        "print(len(dist))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P73bqTZlDC5x",
        "outputId": "06d7b8be-e56b-4e25-a34b-fac570c34bd0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18075\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def buildPharseWords(text, str_len=10):\n",
        "    res=text\n",
        "    data=tokenizerWord.texts_to_sequences(text)\n",
        "    # так как получаем data вида [[],[],[3],[]], то есть часть элементов имеют нулевую длину, а значит неопределены\n",
        "    # потому впишем туда значение 0\n",
        "    for j in range(len(data)):\n",
        "      if len(data[j])==0:\n",
        "        data[j].append(0)\n",
        "    for i in range(str_len):\n",
        "      x=keras.utils.to_categorical(data[i:i+inp_words], num_classes=maxWordsCount) # преобразуем слова в OneHot encoding\n",
        "      inp=x.reshape(1, inp_words,maxWordsCount)\n",
        "      pred=model.predict(inp) # предсказываем ОНЕ четвёртого слова\n",
        "      indx=pred.argmax(axis=1)[0]\n",
        "      data.append([indx])\n",
        "      res+=' '+dist[indx][0] # дописываем строку - достаём из списка кортежей по индексу значение слова\n",
        "    return res"
      ],
      "metadata": {
        "id": "CFQ9iFlKAMcz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res=buildPharseWords('голубые слоны мавритании')\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Bh8xsP1AbNL",
        "outputId": "51a54bce-be7d-40d5-f3f7-0bc4178a8a6a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "голубые слоны мавритании магистр шхиян магистр звезд магистр магистр магистр может анонс магистр\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res=buildPharseWords('лучший ответ на проблемы которые возникли')\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XShfrsvAkfa",
        "outputId": "5b1e65fc-956e-4d95-9513-15e8cfab216b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "лучший ответ на проблемы которые возникли шхиян звезд магистр магистр середину из магистр шхиян магистр врата\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res=buildPharseWords('его жену по приказу царя отправили в дальний монастырь')\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plHpi0VJA1GT",
        "outputId": "3b81911f-ac3f-450c-a3a1-ee90a686d3a7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 125ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "его жену по приказу царя отправили в дальний монастырь сергей магистр году магистр магистр хотел магистр всего сергей сергей\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Большой словарный запас и глубина отслеживания слов =6 как-то не добавили особо смысла получаемого текста...\n",
        "Хотя - модель не дообучилась - 30 эпох оказалось мало - процесс увеличения точности, как и уменьшения потерь шёл уверенно и равномерно."
      ],
      "metadata": {
        "id": "UyJICvr3H5kz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inp_words = 3\n",
        "data=tokenizerWord.texts_to_sequences([texts])\n",
        "res=keras.utils.to_categorical(data[0], num_classes=maxWordsCount)\n",
        "n = res.shape[0]-inp_words\n",
        "X = np.array([res[i:i+inp_words, :] for i in range(n)])\n",
        "Y = res[inp_words:]  # предсказание следующего слова\n",
        "model = Sequential()\n",
        "model.add(Input((inp_words, maxWordsCount)))\n",
        "model.add(SimpleRNN(128, activation='tanh'))\n",
        "model.add(Dense(maxWordsCount, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(X, Y, batch_size=32, epochs=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5Y2FqcHIMmT",
        "outputId": "fe17e3f8-e6f4-4b3b-9f50-6b1386b8bafc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_1 (SimpleRNN)    (None, 128)               144512    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1000)              129000    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 273512 (1.04 MB)\n",
            "Trainable params: 273512 (1.04 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "1529/1529 [==============================] - 9s 5ms/step - loss: 5.7037 - accuracy: 0.0630\n",
            "Epoch 2/30\n",
            "1529/1529 [==============================] - 7s 5ms/step - loss: 5.3647 - accuracy: 0.0972\n",
            "Epoch 3/30\n",
            "1529/1529 [==============================] - 8s 5ms/step - loss: 5.0767 - accuracy: 0.1191\n",
            "Epoch 4/30\n",
            "1529/1529 [==============================] - 8s 5ms/step - loss: 4.8104 - accuracy: 0.1367\n",
            "Epoch 5/30\n",
            "1529/1529 [==============================] - 8s 5ms/step - loss: 4.5708 - accuracy: 0.1507\n",
            "Epoch 6/30\n",
            "1529/1529 [==============================] - 7s 5ms/step - loss: 4.3534 - accuracy: 0.1661\n",
            "Epoch 7/30\n",
            "1529/1529 [==============================] - 8s 5ms/step - loss: 4.1660 - accuracy: 0.1789\n",
            "Epoch 8/30\n",
            "1529/1529 [==============================] - 8s 5ms/step - loss: 3.9965 - accuracy: 0.1924\n",
            "Epoch 9/30\n",
            "1529/1529 [==============================] - 7s 5ms/step - loss: 3.8484 - accuracy: 0.2062\n",
            "Epoch 10/30\n",
            "1529/1529 [==============================] - 8s 5ms/step - loss: 3.7135 - accuracy: 0.2180\n",
            "Epoch 11/30\n",
            "1529/1529 [==============================] - 8s 5ms/step - loss: 3.5924 - accuracy: 0.2337\n",
            "Epoch 12/30\n",
            "1529/1529 [==============================] - 8s 5ms/step - loss: 3.4815 - accuracy: 0.2469\n",
            "Epoch 13/30\n",
            "1529/1529 [==============================] - 8s 5ms/step - loss: 3.3799 - accuracy: 0.2607\n",
            "Epoch 14/30\n",
            "1529/1529 [==============================] - 8s 5ms/step - loss: 3.2890 - accuracy: 0.2742\n",
            "Epoch 15/30\n",
            "1529/1529 [==============================] - 8s 5ms/step - loss: 3.2028 - accuracy: 0.2831\n",
            "Epoch 16/30\n",
            "1529/1529 [==============================] - 8s 5ms/step - loss: 3.1221 - accuracy: 0.2998\n",
            "Epoch 17/30\n",
            "1529/1529 [==============================] - 8s 5ms/step - loss: 3.0476 - accuracy: 0.3121\n",
            "Epoch 18/30\n",
            "1529/1529 [==============================] - 8s 5ms/step - loss: 2.9770 - accuracy: 0.3252\n",
            "Epoch 19/30\n",
            "1529/1529 [==============================] - 7s 5ms/step - loss: 2.9100 - accuracy: 0.3407\n",
            "Epoch 20/30\n",
            "1529/1529 [==============================] - 8s 5ms/step - loss: 2.8476 - accuracy: 0.3515\n",
            "Epoch 21/30\n",
            "1529/1529 [==============================] - 8s 5ms/step - loss: 2.7880 - accuracy: 0.3621\n",
            "Epoch 22/30\n",
            "1529/1529 [==============================] - 7s 5ms/step - loss: 2.7311 - accuracy: 0.3720\n",
            "Epoch 23/30\n",
            "1529/1529 [==============================] - 8s 5ms/step - loss: 2.6790 - accuracy: 0.3807\n",
            "Epoch 24/30\n",
            "1529/1529 [==============================] - 8s 5ms/step - loss: 2.6266 - accuracy: 0.3942\n",
            "Epoch 25/30\n",
            "1529/1529 [==============================] - 8s 5ms/step - loss: 2.5767 - accuracy: 0.4068\n",
            "Epoch 26/30\n",
            "1529/1529 [==============================] - 8s 5ms/step - loss: 2.5314 - accuracy: 0.4137\n",
            "Epoch 27/30\n",
            "1529/1529 [==============================] - 8s 5ms/step - loss: 2.4839 - accuracy: 0.4227\n",
            "Epoch 28/30\n",
            "1529/1529 [==============================] - 8s 5ms/step - loss: 2.4410 - accuracy: 0.4354\n",
            "Epoch 29/30\n",
            "1529/1529 [==============================] - 8s 5ms/step - loss: 2.4008 - accuracy: 0.4417\n",
            "Epoch 30/30\n",
            "1529/1529 [==============================] - 8s 5ms/step - loss: 2.3606 - accuracy: 0.4529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res=buildPharseWords('голубые слоны мавритании')\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VV4h3XMrKL6b",
        "outputId": "0637ac61-3460-463e-9399-7e0f976419e7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 102ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "голубые слоны мавритании сергей пикник шхиян шхиян сергей сергей магистр сергей новых сергей\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res=buildPharseWords('лучший ответ на проблемы которые возникли')\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbH8jkTCKY4U",
        "outputId": "6c335e68-742c-4e08-aec8-f7de9ca61150"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "лучший ответ на проблемы которые возникли шхиян шхиян сергей шхиян анонс сергей сергей невозможно магистр сергей\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dist[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLlnAjL-KmWM",
        "outputId": "77591bb4-d591-43ad-d373-7d462efc3cbe"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('черный', 5),\n",
              " ('магистр', 57),\n",
              " ('сергей', 1),\n",
              " ('шхиян', 1),\n",
              " ('анонс', 1),\n",
              " ('он', 610),\n",
              " ('хотел', 31),\n",
              " ('всего', 50),\n",
              " ('лишь', 6),\n",
              " ('съездить', 2),\n",
              " ('на', 1140),\n",
              " ('пикник', 1),\n",
              " ('но', 374),\n",
              " ('врата', 1),\n",
              " ('времени', 69),\n",
              " ('отворились', 1),\n",
              " ('и', 2594),\n",
              " ('забросили', 1),\n",
              " ('его', 303),\n",
              " ('в', 1839)]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Чего она так к сергею шхияну привязалась?!"
      ],
      "metadata": {
        "id": "dGeT0q-UKzB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res=buildPharseWords('его жену по приказу царя отправили в дальний монастырь')\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7IHs68XLFVk",
        "outputId": "7add2083-1f1d-4faa-945d-59dd18edf5a7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "его жену по приказу царя отправили в дальний монастырь сергей сергей сергей сергей сергей пикник шхиян шхиян сергей сергей\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В целом - полный бред."
      ],
      "metadata": {
        "id": "5W23-_KdLN5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X, Y, batch_size=256, epochs=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXvnOh5bLRRD",
        "outputId": "28dd9304-4a18-4840-9571-7769fb47f949"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "192/192 [==============================] - 3s 16ms/step - loss: 2.0460 - accuracy: 0.5376\n",
            "Epoch 2/30\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 2.0020 - accuracy: 0.5511\n",
            "Epoch 3/30\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.9896 - accuracy: 0.5555\n",
            "Epoch 4/30\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 1.9821 - accuracy: 0.5567\n",
            "Epoch 5/30\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.9770 - accuracy: 0.5574\n",
            "Epoch 6/30\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.9719 - accuracy: 0.5583\n",
            "Epoch 7/30\n",
            "192/192 [==============================] - 3s 16ms/step - loss: 1.9658 - accuracy: 0.5590\n",
            "Epoch 8/30\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 1.9623 - accuracy: 0.5589\n",
            "Epoch 9/30\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.9570 - accuracy: 0.5612\n",
            "Epoch 10/30\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.9513 - accuracy: 0.5623\n",
            "Epoch 11/30\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.9456 - accuracy: 0.5623\n",
            "Epoch 12/30\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 1.9383 - accuracy: 0.5620\n",
            "Epoch 13/30\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.9323 - accuracy: 0.5640\n",
            "Epoch 14/30\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.9250 - accuracy: 0.5666\n",
            "Epoch 15/30\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 1.9156 - accuracy: 0.5671\n",
            "Epoch 16/30\n",
            "192/192 [==============================] - 3s 16ms/step - loss: 1.9093 - accuracy: 0.5709\n",
            "Epoch 17/30\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.8983 - accuracy: 0.5707\n",
            "Epoch 18/30\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.8867 - accuracy: 0.5738\n",
            "Epoch 19/30\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 1.8776 - accuracy: 0.5748\n",
            "Epoch 20/30\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.8669 - accuracy: 0.5769\n",
            "Epoch 21/30\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.8582 - accuracy: 0.5774\n",
            "Epoch 22/30\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.8468 - accuracy: 0.5819\n",
            "Epoch 23/30\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 1.8348 - accuracy: 0.5852\n",
            "Epoch 24/30\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.8223 - accuracy: 0.5859\n",
            "Epoch 25/30\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.8117 - accuracy: 0.5896\n",
            "Epoch 26/30\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.8008 - accuracy: 0.5907\n",
            "Epoch 27/30\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 1.7889 - accuracy: 0.5958\n",
            "Epoch 28/30\n",
            "192/192 [==============================] - 3s 15ms/step - loss: 1.7761 - accuracy: 0.5969\n",
            "Epoch 29/30\n",
            "192/192 [==============================] - 3s 17ms/step - loss: 1.7664 - accuracy: 0.5992\n",
            "Epoch 30/30\n",
            "192/192 [==============================] - 4s 19ms/step - loss: 1.7555 - accuracy: 0.6014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res=buildPharseWords('его жену по приказу царя отправили в дальний монастырь')\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5P33S8APLzML",
        "outputId": "89ed3fec-8a28-458c-a5d7-ede3b32b17b6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "его жену по приказу царя отправили в дальний монастырь магистр сергей сергей магистр магистр пикник анонс шхиян магистр сергей\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Что-то там не то с архитектурой сети."
      ],
      "metadata": {
        "id": "oNh8x_hQL6QE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inp_words = 3\n",
        "data=tokenizerWord.texts_to_sequences([texts])\n",
        "res=keras.utils.to_categorical(data[0], num_classes=maxWordsCount)\n",
        "n = res.shape[0]-inp_words\n",
        "X = np.array([res[i:i+inp_words, :] for i in range(n)])\n",
        "Y = res[inp_words:]  # предсказание следующего слова\n",
        "model = Sequential()\n",
        "model.add(Input((inp_words, maxWordsCount)))\n",
        "model.add(SimpleRNN(128, activation='tanh'))\n",
        "model.add(Dense(maxWordsCount, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(X, Y, batch_size=64, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Tx2GrdiMIHs",
        "outputId": "747f2f13-53f2-4bc2-cb64-5bf0a9c843fc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn_2 (SimpleRNN)    (None, 128)               144512    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1000)              129000    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 273512 (1.04 MB)\n",
            "Trainable params: 273512 (1.04 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "765/765 [==============================] - 6s 7ms/step - loss: 5.7495 - accuracy: 0.0591\n",
            "Epoch 2/10\n",
            "765/765 [==============================] - 5s 6ms/step - loss: 5.4840 - accuracy: 0.0872\n",
            "Epoch 3/10\n",
            "765/765 [==============================] - 5s 7ms/step - loss: 5.2451 - accuracy: 0.1083\n",
            "Epoch 4/10\n",
            "765/765 [==============================] - 5s 6ms/step - loss: 5.0257 - accuracy: 0.1245\n",
            "Epoch 5/10\n",
            "765/765 [==============================] - 5s 6ms/step - loss: 4.8211 - accuracy: 0.1395\n",
            "Epoch 6/10\n",
            "765/765 [==============================] - 5s 7ms/step - loss: 4.6361 - accuracy: 0.1505\n",
            "Epoch 7/10\n",
            "765/765 [==============================] - 5s 6ms/step - loss: 4.4665 - accuracy: 0.1602\n",
            "Epoch 8/10\n",
            "765/765 [==============================] - 5s 7ms/step - loss: 4.3108 - accuracy: 0.1727\n",
            "Epoch 9/10\n",
            "765/765 [==============================] - 5s 6ms/step - loss: 4.1716 - accuracy: 0.1818\n",
            "Epoch 10/10\n",
            "765/765 [==============================] - 5s 7ms/step - loss: 4.0406 - accuracy: 0.1937\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res=buildPharseWords('его жену по приказу царя отправили в дальний монастырь')\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEOGKZ1BM8Hc",
        "outputId": "b8af7f41-0791-41d2-dd72-0ecae066d72e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 152ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "1/1 [==============================] - 0s 13ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "его жену по приказу царя отправили в дальний монастырь может его сергей сергей сергей пикник шхиян сергей может его\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Уменьшение количества эпох обучения - тоже не слишком добавило разнообразия предлагаемым словам"
      ],
      "metadata": {
        "id": "bbO07e6GNGdT"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 32-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "7a329d123903b4c57951128023de9a6a186d692eb5a1f857b66f6831ce5b77d9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}